{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset after generated using wikiWho for authorship and segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17243, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('../dataset/wiki/opinions.csv')\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add language and datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds.loc[ds.page_title.str.startswith('Disc'), 'lang'] = 'es'\n",
    "ds.loc[ds.page_title.str.startswith('Talk'), 'lang'] = 'en'\n",
    "ds['creation_dt'] = pd.to_datetime(ds['timestamp'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds['revision_uid'] = ds.apply(lambda row: '-'.join([str(row['page_id']), str(row['revision_id'])]) , axis=1) \n",
    "ds['turn_uid'] = ds.apply(lambda row: '-'.join([str(row['revision_uid']), str(row['turn_id'])]) , axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter opinion with types detected such as: HMTL tags , or bots edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12104, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds[~ds.type.str.startswith('auto_')]\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add country info using the page url to match countries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_url(row):\n",
    "    url = row['page_title'].replace(' ', '_')\n",
    "    url = 'https://en.wikipedia.org/wiki/' + url if row['lang'] == 'en' else 'https://es.wikipedia.org/wiki/' + url\n",
    "    return url\n",
    "\n",
    "ds['page_url'] = ds.apply(lambda row: build_url(row), axis=1)\n",
    "countries = pd.read_csv('../dataset/wiki/countries.csv')\n",
    "ds2 = pd.merge(ds, countries, left_on='page_url', right_on='wiki', how='left', suffixes=('', '_y'))\n",
    "del ds2['lang_y']\n",
    "del ds2['wiki']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds2.to_csv('../dataset/wiki/opinions_preprocessed.csv', index=False, quoting=csv.QUOTE_ALL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
