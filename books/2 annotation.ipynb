{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12104, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('../dataset/wiki/opinions_preprocessed.csv')\n",
    "ds = ds.reset_index()\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate the sample for each language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = ds[ds.page_title.str.contains('Talk') & ~ds.type.str.startswith('auto') & ~ds.topic.isnull()]\n",
    "sample = sample[(~sample.topic.str.contains('links'))]\n",
    "sample = sample.sample(500)\n",
    "sample.to_csv('../dataset/wiki/samples_en.csv', index=False, header=True)\n",
    "\n",
    "sample = ds[ds.page_title.str.contains('Discu') & ~ds.type.str.startswith('auto') & ~ds.topic.isnull()]\n",
    "sample = sample[(~sample.topic.str.contains('links'))]\n",
    "sample = sample.sample(500)\n",
    "sample.to_csv('../dataset/wiki/samples_es.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge annotated opinions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after annotating, merge both languages samples files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en sample size:(500, 17)\n",
      "es sample size:(500, 17)\n",
      "merged & filtered annotated size:(393, 17)\n"
     ]
    }
   ],
   "source": [
    "ds_annotated = pd.read_csv('../dataset/wiki/samples_en_annotated.csv')\n",
    "print('en sample size:{}'.format(ds_annotated.shape))\n",
    "ds_annotated_es = pd.read_csv('../dataset/wiki/samples_es_annotated.csv')\n",
    "print('es sample size:{}'.format(ds_annotated_es.shape))\n",
    "ds_annotated = ds_annotated.append(ds_annotated_es, ignore_index=True)\n",
    "ds_annotated = ds_annotated[~ds_annotated.stance1.isnull()]\n",
    "print('merged & filtered annotated size:{}'.format(ds_annotated.shape))\n",
    "ds_annotated.to_csv('../dataset/wiki/samples_annotated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge sentiment annotated opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12104, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_annotated_sent = pd.read_csv('../dataset/wiki/opinions_annotated_sent.csv')\n",
    "ds_annotated_sent = ds_annotated_sent.reset_index()\n",
    "ds_annotated_sent = ds_annotated_sent[['index','sent_score', 'sent_magnitude']]\n",
    "ds_annotated_sent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12104, 22)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['index', 'page_id', 'page_title', 'revision_id', 'turn_id',\n",
       "       'contributor', 'timestamp', 'topic', 'raw', 'text', 'type', 'lang',\n",
       "       'creation_dt', 'revision_uid', 'turn_uid', 'page_url', 'country', 'cc2',\n",
       "       'cc3', 'area', 'sent_score', 'sent_magnitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_merged = ds.merge(ds_annotated_sent, on=['index'],how='left', copy=False,suffixes=('', '_y'))\n",
    "#ds_merged = pd.concat([ds, ds_annotated_sent], axis=1)\n",
    "print(ds_merged.shape)\n",
    "ds_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "-1.0    1699\n",
       " 0.0    2569\n",
       " 1.0     756\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_norm_sent(s):\n",
    "    if np.isnan(s):\n",
    "        return np.nan \n",
    "    if s > 0.20:\n",
    "        return 1\n",
    "    elif s < -0.20:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "ds_merged['sentiment'] = np.nan\n",
    "ds_merged['sentiment'] = ds_merged.sent_score.apply(lambda s: get_norm_sent(s))\n",
    "\n",
    "ds_merged[~ds_merged.sentiment.isnull()].groupby('sentiment').size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge unannotated and annotated datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is tricky, in the original sample files, we didn't have key fields (revision_id, turn_id, opinion_id), so we had to merge using other fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12104, 35)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['index', 'page_id', 'page_title', 'revision_id', 'turn_id',\n",
       "       'contributor', 'timestamp', 'topic', 'raw', 'text', 'type', 'lang',\n",
       "       'creation_dt', 'revision_uid', 'turn_uid', 'page_url', 'country', 'cc2',\n",
       "       'cc3', 'area', 'sent_score', 'sent_magnitude', 'sentiment',\n",
       "       'page_title_y', 'link', 'text_y', 'type1', 'stance1', 'sentiment1',\n",
       "       'type2', 'stance2', 'sentiment2', 'type_y', 'stance', 'sentiment_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_merged = ds_merged.merge(ds_annotated, on=['page_id','timestamp', 'contributor','topic', 'raw'],how='left', copy=False,suffixes=('', '_y'))\n",
    "print(ds_merged.shape)\n",
    "ds_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manually merge type column, we kept the labels generated automatically in the dataset generation and only update those opinions that were annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_merged['type'] = ds_merged.apply(lambda row: row['type_y'] if not pd.isnull(row['type_y']) else row['type'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete duplicated columns in merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del ds_merged['page_title_y']\n",
    "del ds_merged['text_y']\n",
    "del ds_merged['type_y']\n",
    "del ds_merged['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds_merged.to_csv('../dataset/wiki/opinions_annotated.csv', index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>pages</th>\n",
       "      <th>editors</th>\n",
       "      <th>revisions</th>\n",
       "      <th>turns</th>\n",
       "      <th>opinions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>13</td>\n",
       "      <td>57</td>\n",
       "      <td>88</td>\n",
       "      <td>124</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>es</td>\n",
       "      <td>12</td>\n",
       "      <td>84</td>\n",
       "      <td>190</td>\n",
       "      <td>195</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang  pages  editors  revisions  turns  opinions\n",
       "0   en     13       57         88    124       168\n",
       "1   es     12       84        190    195       223"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = ds_merged[~ds_merged.stance.isnull()].groupby('lang')\n",
    "group = group.agg({'page_id':'nunique', 'contributor': 'nunique','revision_uid':'nunique', 'turn_uid':'nunique', 'text':'count'}).reset_index()\n",
    "group.rename(columns={'page_id': 'pages', 'contributor': 'editors', 'text': 'opinions',\n",
    "                   'revision_uid': 'revisions', 'turn_uid':'turns'}, inplace=True)\n",
    "group.to_csv('../results/ds_annotated_stats.csv', index=False)\n",
    "group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# agreement stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## type agreeement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_annotated = ds_annotated[ds_annotated.type1!='unknown']\n",
    "ds_annotated.columns\n",
    "ds_annotated.loc[:,'type_agreement'] = ds_annotated.apply(lambda r: 1 if r['type1'] == r['type2'] else 0, axis=1)\n",
    "ds_annotated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acknowledge nan\n",
      "agreement 0.0\n",
      "authority nan\n",
      "bot_sign nan\n",
      "content 0.229110512129\n",
      "coordinating 0.0\n",
      "criticism 0.480519480519\n",
      "disagreement 0.0\n",
      "doubing 0.177215189873\n",
      "doubting -0.0526315789474\n",
      "grammatical 0.0\n",
      "insulting 0.0\n",
      "praise 0.6\n",
      "references 0.736082474227\n",
      "reverts nan\n",
      "sarcasm nan\n",
      "spam 0.0\n",
      "statement 0.462277091907\n",
      "vandalism 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:350: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "types = ds_annotated.groupby(['type'])\n",
    "\n",
    "for name, group in types:\n",
    "    k = cohen_kappa_score(group.stance1, group.stance2)\n",
    "    print(name, k)\n",
    "    ds_annotated.loc[ds_annotated.type1==name, 'k'] = k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>A</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acknowledge</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agreement</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>authority</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bot sign</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>content</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          type         A         k\n",
       "0  acknowledge  0.000000       NaN\n",
       "1    agreement  0.808511  0.000000\n",
       "2    authority  1.000000       NaN\n",
       "3     bot sign  1.000000       NaN\n",
       "4      content  0.000000  0.229111"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stats = types.agg({'type_agreement': 'mean', 'k': 'mean'})\n",
    "#stats.head()\n",
    "#stats = stats.pivot_table(index='type', columns='lang', values='count', fill_value=0).reset_index()\n",
    "#stats['']\n",
    "stats = stats.reset_index()\n",
    "stats['type'] = stats['type'].str.replace('_', ' ')\n",
    "stats.rename(columns={'type_agreement':'A'}, inplace=True)\n",
    "stats.to_csv('../results/types_agreeement.csv', index=False)\n",
    "stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>stance</th>\n",
       "      <th>type</th>\n",
       "      <th>against</th>\n",
       "      <th>neutral</th>\n",
       "      <th>favor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acknowledge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agreement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>authority</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bot_sign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>content</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "stance         type  against  neutral  favor\n",
       "0       acknowledge      NaN      NaN    1.0\n",
       "1         agreement      NaN      NaN   47.0\n",
       "2         authority      NaN      1.0    NaN\n",
       "3          bot_sign      NaN      2.0    NaN\n",
       "4           content     10.0      1.0   11.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types2 = ds_annotated.groupby(['type','stance'])\n",
    "stats2 = types2.size().reset_index(name='count')\n",
    "stats2 = stats2.pivot(index='type', columns='stance', values='count')\n",
    "stats2 = stats2.reset_index()\n",
    "stats2.rename(columns={-1.0: 'against', 0.0: 'neutral', 1.0: 'favor'}, inplace=True)\n",
    "stats2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_f = pd.merge(stats, stats2, on='type')\n",
    "stats_f.to_csv('../results/stance_agreeement.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
